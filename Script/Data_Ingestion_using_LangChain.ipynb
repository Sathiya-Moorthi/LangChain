{"cells":[{"cell_type":"markdown","id":"84e2aad0","metadata":{"id":"84e2aad0"},"source":["**Data Ingestion or Loading**"]},{"cell_type":"code","execution_count":null,"id":"ac1735f2","metadata":{"id":"ac1735f2"},"outputs":[],"source":["%pip install langchain-community"]},{"cell_type":"markdown","id":"f4f0ecde","metadata":{"id":"f4f0ecde"},"source":["Loading a Text File"]},{"cell_type":"code","execution_count":null,"id":"d39cc232","metadata":{"collapsed":true,"id":"d39cc232","outputId":"9eeddda7-f2d4-48de-cd43-4df8296819ba"},"outputs":[{"name":"stderr","output_type":"stream","text":["D:\\Gen AI Project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from langchain_community.document_loaders import TextLoader\n","\n","test = TextLoader(r\"D:\\Gen AI Project\\venv\\LangChain\\Input Files\\notes.txt\")"]},{"cell_type":"code","execution_count":null,"id":"7aac1e3e","metadata":{"id":"7aac1e3e","outputId":"78320210-dc41-4506-a191-e2066281a62b"},"outputs":[{"data":{"text/plain":["[Document(metadata={'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\notes.txt'}, page_content='Hi, Welcome to LangChain, Happy Learning!')]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["test.load()"]},{"cell_type":"markdown","id":"dc333732","metadata":{"id":"dc333732"},"source":["Loading a PDF File"]},{"cell_type":"code","execution_count":null,"id":"ddf4afb2","metadata":{"collapsed":true,"id":"ddf4afb2","outputId":"794ca15c-8ad3-4b24-ccad-e0fa4674ba69"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pypdf\n","  Downloading pypdf-6.3.0-py3-none-any.whl.metadata (7.1 kB)\n","Downloading pypdf-6.3.0-py3-none-any.whl (328 kB)\n","Installing collected packages: pypdf\n","Successfully installed pypdf-6.3.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# %pip install pypdf"]},{"cell_type":"code","execution_count":null,"id":"87498b5d","metadata":{"id":"87498b5d","outputId":"fc1d6ced-4265-4c3d-ddb5-675a3c455d5e"},"outputs":[{"name":"stderr","output_type":"stream","text":["D:\\Gen AI Project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from langchain_community.document_loaders import PyPDFLoader\n","\n","test_1 = PyPDFLoader(r\"D:\\Gen AI Project\\venv\\LangChain\\Input Files\\UU_EktaVats_AI_Physics.pdf\")"]},{"cell_type":"code","execution_count":null,"id":"ec94b895","metadata":{"collapsed":true,"id":"ec94b895","outputId":"35900688-c6a2-4bf0-ff02-75cd097b08a1"},"outputs":[{"name":"stderr","output_type":"stream","text":["Ignoring wrong pointing object 8 0 (offset 0)\n","Ignoring wrong pointing object 10 0 (offset 0)\n","Ignoring wrong pointing object 12 0 (offset 0)\n","Ignoring wrong pointing object 24 0 (offset 0)\n","Ignoring wrong pointing object 26 0 (offset 0)\n","Ignoring wrong pointing object 33 0 (offset 0)\n","Ignoring wrong pointing object 35 0 (offset 0)\n","Ignoring wrong pointing object 41 0 (offset 0)\n","Ignoring wrong pointing object 46 0 (offset 0)\n","Ignoring wrong pointing object 48 0 (offset 0)\n","Ignoring wrong pointing object 75 0 (offset 0)\n","Ignoring wrong pointing object 81 0 (offset 0)\n","Ignoring wrong pointing object 83 0 (offset 0)\n","Ignoring wrong pointing object 106 0 (offset 0)\n","Ignoring wrong pointing object 109 0 (offset 0)\n","Ignoring wrong pointing object 120 0 (offset 0)\n","Ignoring wrong pointing object 10 0 (offset 0)\n","Ignoring wrong pointing object 12 0 (offset 0)\n","Ignoring wrong pointing object 24 0 (offset 0)\n","Ignoring wrong pointing object 26 0 (offset 0)\n","Ignoring wrong pointing object 33 0 (offset 0)\n","Ignoring wrong pointing object 35 0 (offset 0)\n","Ignoring wrong pointing object 41 0 (offset 0)\n","Ignoring wrong pointing object 46 0 (offset 0)\n","Ignoring wrong pointing object 48 0 (offset 0)\n","Ignoring wrong pointing object 75 0 (offset 0)\n","Ignoring wrong pointing object 81 0 (offset 0)\n","Ignoring wrong pointing object 83 0 (offset 0)\n","Ignoring wrong pointing object 106 0 (offset 0)\n","Ignoring wrong pointing object 109 0 (offset 0)\n","Ignoring wrong pointing object 120 0 (offset 0)\n","Ignoring wrong pointing object 137 0 (offset 0)\n","Ignoring wrong pointing object 139 0 (offset 0)\n","Ignoring wrong pointing object 150 0 (offset 0)\n","Ignoring wrong pointing object 163 0 (offset 0)\n","Ignoring wrong pointing object 211 0 (offset 0)\n","Ignoring wrong pointing object 233 0 (offset 0)\n","Ignoring wrong pointing object 345 0 (offset 0)\n","Ignoring wrong pointing object 428 0 (offset 0)\n","Ignoring wrong pointing object 513 0 (offset 0)\n","Ignoring wrong pointing object 537 0 (offset 0)\n","Ignoring wrong pointing object 137 0 (offset 0)\n","Ignoring wrong pointing object 139 0 (offset 0)\n","Ignoring wrong pointing object 150 0 (offset 0)\n","Ignoring wrong pointing object 163 0 (offset 0)\n","Ignoring wrong pointing object 211 0 (offset 0)\n","Ignoring wrong pointing object 233 0 (offset 0)\n","Ignoring wrong pointing object 345 0 (offset 0)\n","Ignoring wrong pointing object 428 0 (offset 0)\n","Ignoring wrong pointing object 513 0 (offset 0)\n","Ignoring wrong pointing object 537 0 (offset 0)\n"]},{"data":{"text/plain":["[Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 0, 'page_label': '1'}, page_content='Ekta VatsAssistant Professor, DocentDepartment of Information Technology, Uppsala University (UU)Beijer Researcher, Beijer Laboratory for AI Research, Beijerstiftelsen\\nIntroduction to Large Language Model (LLM)AI in Physics Workshop– April 11, 2025'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 1, 'page_label': '2'}, page_content='Navigating in the Artificial Intelligence Era\\nThe future?\\nImage generated using ChatGPT'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 2, 'page_label': '3'}, page_content='Navigating in the Artificial Intelligence Era\\nThe future?\\nHolographicdisplays, autonomous bicycles, drone deliveriesÅngström à UNGSTROM'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 3, 'page_label': '4'}, page_content='Navigating in the Artificial Intelligence Era\\nGenerative AI – Generating new content!\\nLearn patterns and structure of input data, and generate new samples that exhibit similar characteristics.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 4, 'page_label': '5'}, page_content='Artificial Intelligence\\nGenerative AI\\nAI TaxonomyTechnology that enables computers and machines to simulate human intelligence and problem-solving capabilities'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 5, 'page_label': '6'}, page_content='Artificial IntelligenceMachine LearningDeep Learning\\nGenerative AI\\nAI Taxonomy\\nSubset of AI, focuses on developing systems that can learn from data and make decisions based on data'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 6, 'page_label': '7'}, page_content='AI Evolution Through Decades\\nSource: sk hynix newsroom'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 7, 'page_label': '8'}, page_content='AI Evolution Through Decades\\n2024The Nobel Prizes in Physics and Chemistry goes to AI!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 8, 'page_label': '9'}, page_content=''),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 9, 'page_label': '10'}, page_content='Source – leewayhertz\\nSynthetic image generation\\nSORA: text-to-video model\\nText:Turn the library into a spaceship.Output:\\nSource – Open AI, SORA\\nVideo generation!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 10, 'page_label': '11'}, page_content='Synthetic image generation\\nImage generation!\\nMidjourneyText-to-image models:\\nTwo dogs dressed like roman soldiers on a pirate ship looking at New York City through a spyglass\\nSource – Open AI, DALL·E -2 Source: Twitter, Benjamin Hilton\\nDALL·E\\nAn image of a cat enjoying sprinklers.\\nSource: Microsoft Copilot'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 11, 'page_label': '12'}, page_content='TTS: Text-to-song; STS: Speech-to-singing \\nSynthetic image generation\\nSource – leewayhertz'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 12, 'page_label': '13'}, page_content='Artificial Intelligence\\nMachine Learning\\nDeep Learning\\nGenerative AI\\nLLMs\\nAI Taxonomy\\nSubset of ML, uses Artificial Neural Networks to learn from data\\nSubset of AI, focuses on generating new content\\nSpecific type of Generative AI model that focuses on generating human-like text\\nLLMs: Large Language Models'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 13, 'page_label': '14'}, page_content='Large Language Model (LLM)•A type of language model'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 14, 'page_label': '15'}, page_content='Language Model•Type of machine learning model trained to predict probability distribution over words\\nVi sesimorgon  0.5snart  0.3 på  0.2\\n•Predicts the probability of a word in a sequence based on the previous word'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 15, 'page_label': '16'}, page_content='Language Model•Type of machine learning model trained to predict probability distribution over words\\nVi sesimorgon  0.5snart  0.3 på  0.2\\nGoogle search and advanced language models'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 16, 'page_label': '17'}, page_content='Language Model•Classic definition: Probability distribution over a sequence of tokens•For example, if vocabulary of a set of tokens is V = {ate, ball, cheese, mouse, the}, a language model p might assign:  p(!\"#, $%&\\'#, (!#, !\"#, )\"##\\'#) = 0.02,  p(!\"#, )\"##\\'#, (!#, !\"#, $%&\\'#) = 0.01,  p($%&\\'#, !\"#, !\"#, )\"##\\'#, (!#) = 0.0001. \\nSource: https://stanford-cs324.github.io/winter2022/lectures/introduction/'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 17, 'page_label': '18'}, page_content='Language Model•Classic definition: Probability distribution over a sequence of tokens•For example, if vocabulary of a set of tokens is V = {ate, ball, cheese, mouse, the}, a language model p might assign:  p(!\"#, $%&\\'#, (!#, !\"#, )\"##\\'#) = 0.02,  p(!\"#, )\"##\\'#, (!#, !\"#, $%&\\'#) = 0.01,  p($%&\\'#, !\"#, !\"#, )\"##\\'#, (!#) = 0.0001.•Example: Neural language models - RNNs including LSTMs, Transformers  p(cheese | (!#, !\"#) = some-neural-network(ate, the, cheese)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 18, 'page_label': '19'}, page_content='Large Language Model (LLM)•A type of language model•Why large: •Trained using massive datasets•With the rise of deep learning andavailability of large computational resources, the size of neural language models has increased.\\nImage source: nsc.liu.se\\nBerzelius!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 19, 'page_label': '20'}, page_content='Large Language Model (LLM)\\nSource– cobusgreyling.medium.com\\n2018 20232025: GPT-5?\\nScaling-up – bigger is better?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 20, 'page_label': '21'}, page_content='Architecture\\n•LLM is a type of transformer model•Transformer: •A neural network that learns context and meaning by tracking relationshipsin sequential data'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 21, 'page_label': '22'}, page_content='Architecture\\n•LLM is a type of transformer model•Transformer: •A neural network that learns context and meaning by tracking relationshipsin sequential data•Encoder-decoder architecture•Encoder extracts features from an input sequence•Decoder uses the features to produce an output sentence\\nHur mår du?\\nHow are you?\\nCase: translation\\n(input)\\n(output)TRANSFORMER'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 22, 'page_label': '23'}, page_content='Architecture\\n•LLM is a type of transformer model•Transformer: •A neural network that learns context and meaning by tracking relationshipsin sequential data•Encoder-decoder architecture•Encoder extracts features from an input sequence•Decoder uses the features to produce an output sentence\\n(input)\\n(output)\\nCan be used independently!\\nTRANSFORMER\\nCase: translation\\nHur mår du?\\nHow are you?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 23, 'page_label': '24'}, page_content='Transformer – Recommended Reading•Transformers by Lucas Beyer•Link: https://www.youtube.com/watch?v=EixI6t5oif0•Deep Learning course (1RT720)•Given in period 3•Course responsible: Niklas Wahlström•LLMs & Societal Consequences of AI  (1RT730)•Given in period 1•Course responsible: Ekta Vats'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 24, 'page_label': '25'}, page_content='Types of LLMs'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 25, 'page_label': '26'}, page_content='Types of LLMs•Encoder only: •Suited for tasks that can understand language, •such as toxicity classification and sentiment analysis. \\n•Example: BERT (Bidirectional Encoder Representations from Transformers)\\nSentiment analysis of tweets'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 26, 'page_label': '27'}, page_content='Types of LLMs•Decoder only: •Suited for generating language and content, •such as story writing, blog generation, open-domain Q/A and virtual assistants.\\n•Example: GPT-3 (Generative Pretrained Transformer 3)\\nChatBots'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 27, 'page_label': '28'}, page_content=''),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 28, 'page_label': '29'}, page_content='Types of LLMs•Encoder-decoder: •Combine the encoder and decoder components of the transformer architecture•Suited for both understanding and generating content, •such as translation, text-to-code and summarisations. •Example: T5 (Text-to-Text Transformers) by HuggingFace'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 29, 'page_label': '30'}, page_content='Types of LLMs•Encoder-decoder: •Example: T5 (Text-to-Text Transformers) by HuggingFace.\\nT5“Translate English to Swedish: Thank you very much.” \\n“Tack så mycket.”'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 30, 'page_label': '31'}, page_content='Types of LLMs•Encoder-decoder: •Example: T5 (Text-to-Text Transformers) by HuggingFace.\\nT5\\n“summarize: Sweden became NATO’s newest member on Thursday (7 March 2024), upon depositing its instrument of accession to the North Atlantic Treaty with the Government of the United States in Washington DC. With Sweden’s accession, NATO now counts 32 countries among its members.” \\n“Sweden joined NATO on March 7, 2024, becoming its 32nd member.”'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 31, 'page_label': '32'}, page_content='LLM Lifecycle'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 32, 'page_label': '33'}, page_content='LLM Lifecycle1.Collect training data – e.g. Common Crawl2.Train a LLM – e.g. GPT-33.Adapt it for downstream tasks – e.g. Q/A4.Deploy LLM to users – e.g. Chatbot'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 33, 'page_label': '34'}, page_content='Important\\n Data is the fuel!\\nAI is the engine!\\n•To understand and document the composition of your training dataset\\nFurther reading: https://stanford-cs324.github.io/winter2022/lectures/legality/'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 34, 'page_label': '35'}, page_content='Important•To understand and document the composition of your training dataset•To be aware of copyright law (IPR, licenses), privacy law, high-risk applications\\n•Is training LLM on this data a copyright/privacy violation?•Canit cause intentionalharm –spam, harassment, disinformation, phishingattacks?•AreyoudeployingLLM in healthcareor education?•Githubcodeand licensing\\nFurther reading: https://stanford-cs324.github.io/winter2022/lectures/legality/'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 35, 'page_label': '36'}, page_content='Multimodal LLMs'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 36, 'page_label': '37'}, page_content='Multimodal LLMs•Unimodal LLMs are trained on a single modality of data, such as text•Lack visual context'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 37, 'page_label': '38'}, page_content='Multimodal LLMs•Unimodal LLMs are trained on a single modality of data, such as text•Lack visual context•Multimodal LLMs: •Understand and generate content across multiple modalities,•such as text, images, audio, video, or other sensor data•Vision-language models: •Multimodal models that can learn from images and text'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 38, 'page_label': '39'}, page_content='Vision-Language Models•Main idea: Unify the image and text representation, and feed it to a textual decoder for generation'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 39, 'page_label': '40'}, page_content='Vision-Language Models•Main idea: Unify the image and text representation, and feed it to a textual decoder for generation•Typically consists of two main components: •Vision encoder: extracts image features and encodes them into a format that can be understood by the language decoder. Example: ResNet, ViT•Language decoder: takes these encoded visual features along with any textual input and generates descriptions, or captions, etc. Example: GPT-2, GPT-3'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 40, 'page_label': '41'}, page_content='Vision-Language Models\\nhttps://huggingface.co/blog/vlms'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 41, 'page_label': '42'}, page_content='Vision-Language Models\\nhttps://huggingface.co/blog/vlms'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 42, 'page_label': '43'}, page_content='Contrastive Language-Image Pretraining (CLIP)•CLIP differs from traditional vision-language models \\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\"International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 43, 'page_label': '44'}, page_content='Contrastive Language-Image Pretraining (CLIP)•CLIP differs from traditional vision-language models •It does not generate text descriptions or captions for images•Focuses on learning a joint representation space where images and text can be compared directly\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\"International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 44, 'page_label': '45'}, page_content='Contrastive Language-Image Pretraining (CLIP)•CLIP differs from traditional vision-language models •It does not generate text descriptions or captions for images•Focuses on learning a joint representation space where images and text can be compared directly•Enables various downstream tasks, such as •Zero-shot image classification: classify images into one of several classes, without any prior training or knowledge of the classes•Zero-shot image retrieval, text-based image generation\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\"International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 45, 'page_label': '46'}, page_content='Contrastive Language-Image Pretraining (CLIP)1.Jointly trains a text encoder and an image encoder to predict the correct image—text pair\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\"International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 46, 'page_label': '47'}, page_content='Contrastive Language-Image Pretraining (CLIP)1.Jointly trains a text encoder and an image encoder to predict the correct image—text pair\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\"International conference on machine learning. PMLR, 2021.\\nContrastive Pre-trainingText embeddings\\nImage embeddings\\nTransformer\\n(ResNet or ViT)\\nContrastive learning framework•Maximize the cosine similarities between correct image-text pairs•Minimizethe cosine similarities for dissimilarpairs (non-diagonal elements)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 47, 'page_label': '48'}, page_content='Contrastive Language-Image Pretraining (CLIP)2.Converts training dataset classes into captions\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\"International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 48, 'page_label': '49'}, page_content='Contrastive Language-Image Pretraining (CLIP)3.Estimates the best caption for the given input image for zero-shot prediction•Calculate similarity between an image vector and multiple caption vectors, selecting the one with the highest score\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\"International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 49, 'page_label': '50'}, page_content='Contrastive Language-Image Pretraining (CLIP)3.Estimates the best caption for the given input image for zero-shot prediction•Calculate similarity between an image vector and multiple caption vectors, selecting the one with the highest score\\n•Trained on 400M image-text pairs•CLIP can perform image tasks using only text, no extra training needed•CLIP encodings + decoder models (e.g. GPT-2) => image captioning'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 50, 'page_label': '51'}, page_content='Some Interesting Examples'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 51, 'page_label': '52'}, page_content='Modern Handwriting Recognition using ChatGPT\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Can you recognise this text?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 52, 'page_label': '53'}, page_content='Modern Handwriting Recognition using ChatGPT\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Can you recognise this text?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 53, 'page_label': '54'}, page_content='Old Handwriting Recognition using ChatGPT\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Can you read this?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 54, 'page_label': '55'}, page_content='Old Handwriting Recognition using ChatGPT\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Can you read this?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 55, 'page_label': '56'}, page_content='Ancient Handwriting Recognition using Microsoft Copilot\\nNota bene is the Latin phrase meaning note well'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 56, 'page_label': '57'}, page_content='OCR and Document Question Answering•Text…\\nhttps://huggingface.co/docs/transformers/main/en/tasks/document_question_answering\\nQuestion: Who is in cc in this letter? Answer: T.F. Riehl'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 57, 'page_label': '58'}, page_content='Understanding Complex Parking Signs – ChatGPT\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Suppose it is Wednesday and the time is 4PM. Am I allowed to park my car at this spot?\\nAnyone?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 58, 'page_label': '59'}, page_content='Understanding Complex Parking Signs – GPT-4V\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Suppose it is Wednesday and the time is 4PM. Am I allowed to park my car at this spot?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 59, 'page_label': '60'}, page_content='Visual Question Answering\\nMarino, Kenneth, et al. \"Ok-vqa: A visual question answering benchmark requiring external knowledge.\"Proceedings of the IEEE/cvfconference on computer vision and pattern recognition. 2019.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 60, 'page_label': '61'}, page_content='Visual Question Answering\\nLiu, Haotian, et al. \"Visual instruction tuning.\"Advances in neural information processing systems36 (2024).\\nLLaVA: Large Language and Vision Assistant -CLIP visual encoder + Vicuna LLM'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 61, 'page_label': '62'}, page_content='Visual Question Answering\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nLLaVA: Large Language and Vision Assistant -CLIP visual encoder + Vicuna LLM'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 62, 'page_label': '63'}, page_content='Whisper by OpenAI•Speech-to-text model, performs:•Speech recognition•Speech translation•Spoken language identification•Voice activity detection'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 63, 'page_label': '64'}, page_content='Focus: Swedish speech\\nImage source: LinkedIn'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 64, 'page_label': '65'}, page_content='LLMs and Video Analysis\\nPlatform: Azure AI'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 65, 'page_label': '66'}, page_content='Challenges and limitations'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 66, 'page_label': '67'}, page_content='Challenges and Limitations•Out-of-date training data\\nThis example was tested on 10 March, 2025'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 67, 'page_label': '68'}, page_content='Challenges and Limitations•Hallucinations•Facts are sometimes extrapolated, •LLMs try to invent facts, •articulating the inaccurate information in a convincing way.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 68, 'page_label': '69'}, page_content='Challenges and Limitations•Hallucinations•Facts are sometimes extrapolated, •LLMs try to invent facts, •articulating the inaccurate information in a convincing way.\\nThis example was tested in Spring 2024'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 69, 'page_label': '70'}, page_content='Challenges and Limitations•Hallucinations•Facts are sometimes extrapolated, •LLMs try to invent facts, •articulating the inaccurate information in a convincing way.\\nTested: October 2024'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 70, 'page_label': '71'}, page_content='Challenges and Limitations\\nTested: March 2025'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 71, 'page_label': '72'}, page_content='Challenges and Limitations•Hallucinations'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 72, 'page_label': '73'}, page_content='Challenges and Limitations•Hallucinations\\nWhat is the correct answer?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 73, 'page_label': '74'}, page_content='Challenges and Limitations•Hallucinations\\n•It is a language model!•Training data lacks focus on math concepts and problem-solving.\\n5,162,060'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 74, 'page_label': '75'}, page_content='Hallucinations, Case – Law\\nThis example was shared by a lawyer'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 75, 'page_label': '76'}, page_content='Hallucinations, Case – Law\\nThis example was shared by a lawyer'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 76, 'page_label': '77'}, page_content='Hallucinations, Case – Law\\nMicrosoft Copilot did not hallucinate!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 77, 'page_label': '78'}, page_content='Hallucinations, Case – MiniGPT-4\\nSource: MiniGPT-4 by HuggingFace'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 78, 'page_label': '79'}, page_content='Hallucinations, Case – MiniGPT-4\\nSource: MiniGPT-4 by HuggingFace'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 79, 'page_label': '80'}, page_content='Hallucinations, Case - HTRFlow\\nHTRFlow modelBevittna  (Bevittna translates to witness)\\nSource: https://huggingface.co/spaces/Riksarkivet/htr_demo (2023)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 80, 'page_label': '81'}, page_content='Potential Solution: Retrieval Augmented Generation (RAG)\\n•Helps address both hallucinations and out-of-date training data issues'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 81, 'page_label': '82'}, page_content='Retrieval Augmented Generation (RAG)\\n•Build LLMs with current and reliable information•Extending its utility to specific data sources•Allows LLMs to go beyond their knowledge-base, enabling them to access real-time data, and providing up to date responses\\n•Example use case: Improve Math Q/A'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 82, 'page_label': '83'}, page_content='Retrieval Augmented Generation (RAG)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 83, 'page_label': '84'}, page_content='Retrieval Augmented Generation (RAG)\\nThis example was on 10 March, 2025'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 84, 'page_label': '85'}, page_content='RAG Example Projects from UU course on LLMs\\n•Teaching LLM to teach AI'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 85, 'page_label': '86'}, page_content='RAG Example Projects from UU course on LLMs\\n•Teaching LLM to teach AI \\n•Chat with 1177.se'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 86, 'page_label': '87'}, page_content='RAG Example Projects from UU course on LLMs\\n•Teaching LLM to teach AI \\n•Chat with 1177.se\\n•LLM powered teaching assistant for Smarter Education•Exercise sheet generation•Based on age, grade and interest of the child'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 87, 'page_label': '88'}, page_content='Challenges and Limitations•Bias and misinformation as ethical concerns\\nSocial Biases in Language Models: http://uu.diva-portal.org/smash/get/diva2:1696604/FULLTEXT01.pdf'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 88, 'page_label': '89'}, page_content=\"Challenges and Limitations•Bias and misinformation as ethical concerns\\n•Key pointer: •LLM has inherited society's stereotypes due to the training data being fed into it.•Other cases: voice assistants and FaceID\"),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 89, 'page_label': '90'}, page_content='Voice Assistants and Accent Bias\\nSource: https://www.amazon.science/blog/how-alexa-learned-to-speak-with-an-irish-accent (2023)\\n•Data problem!•The higher the quantity and diversity of speech samples in a corpus, the more accurate the resulting model\\nAmazon researchers improved Irish-accented training data by using a voice conversion model'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 90, 'page_label': '91'}, page_content='Face ID and Limitations\\nSource: https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212  (2018)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 91, 'page_label': '92'}, page_content='Face ID and Limitations\\nSource: https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212  (2018)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 92, 'page_label': '93'}, page_content='Face ID and Limitations•This bias arise from the imbalance in the training data•Lighting conditions: Darker skin tones might reflect less light, potentially affecting recognition accuracy'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 93, 'page_label': '94'}, page_content='Face ID and Limitations•This bias arise from the imbalance in the training data•Lighting conditions: Darker skin tones might reflect less light, potentially affecting recognition accuracy•Modern face recognition systems:•Diverse training data•Algorithmic improvements •Aim to achieve robust performance, regardless of skin tone or lighting conditions.•Biases can still persist'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 94, 'page_label': '95'}, page_content='Future Insights!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 95, 'page_label': '96'}, page_content='Future Insights!\\nScaling-up – bigger is better?\\n•Quantitatively: different capabilities\\n•Qualitatively: different societal impact'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 96, 'page_label': '97'}, page_content='Future Insights!\\nScaling-up – bigger is better?\\n In-Context Learning\\nhttps://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec04.pdf\\nZero-shot\\nOne-shot\\nFew-shot'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 97, 'page_label': '98'}, page_content='Future Insights!\\nScaling-up – bigger is better?\\n In-Context Learning\\nAI powered precision in healthcare\\nAnalyse medical images, and using LLMs correlate medical findings with patient history, delivering comprehensive diagnostics and potential treatment options. \\nAlso… Applications in Physics!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 98, 'page_label': '99'}, page_content='Advanced Multimodal LLMs•Example: NExT-GPT (Any-to-Any Multimodal LLM)•Text + Video à Text + Image\\nhttps://next-gpt.github.io\\nImageBind by Meta6 modalities:Images/videos,Audio, Text,Depth, Thermal,Inertial measurement units (IMUs)+ Diffusion Models (generation)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 99, 'page_label': '100'}, page_content='You can select “off” for this option, in your ChatGPT settings.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 100, 'page_label': '101'}, page_content='We conducted an exam for •Total 10 questions•Following are our findings:•Both excel in creative thinking, image generation and summarization. •ChatGPT struggles with legal reasoning but excels in math. •Neither handles old handwriting well.•Overall, score for Copilot was higher.\\n•Curious to know how it works in Physics…\\nLink'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250411085308Z00'00'\", 'moddate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'page': 101, 'page_label': '102'}, page_content='Thank you!Email    : ekta.vats@it.uu.seWebpage: https://www.ektavats.se')]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["test_1.load()"]},{"cell_type":"code","execution_count":null,"id":"df397748","metadata":{"collapsed":true,"id":"df397748","outputId":"6760e330-18c7-4efb-e5ff-8f2cb6d55db7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting PyMuPDF\n","  Downloading pymupdf-1.26.6-cp310-abi3-win_amd64.whl.metadata (3.4 kB)\n","Downloading pymupdf-1.26.6-cp310-abi3-win_amd64.whl (18.4 MB)\n","   ---------------------------------------- 0.0/18.4 MB ? eta -:--:--\n","   ---------------------------------------- 0.0/18.4 MB ? eta -:--:--\n","    --------------------------------------- 0.3/18.4 MB ? eta -:--:--\n","   - -------------------------------------- 0.8/18.4 MB 2.1 MB/s eta 0:00:09\n","   --- ------------------------------------ 1.6/18.4 MB 2.5 MB/s eta 0:00:07\n","   ---- ----------------------------------- 2.1/18.4 MB 2.7 MB/s eta 0:00:06\n","   ------ --------------------------------- 2.9/18.4 MB 2.9 MB/s eta 0:00:06\n","   ------- -------------------------------- 3.7/18.4 MB 3.2 MB/s eta 0:00:05\n","   --------- ------------------------------ 4.2/18.4 MB 3.1 MB/s eta 0:00:05\n","   ---------- ----------------------------- 4.7/18.4 MB 3.0 MB/s eta 0:00:05\n","   ----------- ---------------------------- 5.2/18.4 MB 2.9 MB/s eta 0:00:05\n","   ------------- -------------------------- 6.0/18.4 MB 3.0 MB/s eta 0:00:05\n","   -------------- ------------------------- 6.6/18.4 MB 3.0 MB/s eta 0:00:04\n","   --------------- ------------------------ 7.3/18.4 MB 3.1 MB/s eta 0:00:04\n","   ----------------- ---------------------- 8.1/18.4 MB 3.1 MB/s eta 0:00:04\n","   ------------------- -------------------- 8.9/18.4 MB 3.2 MB/s eta 0:00:03\n","   --------------------- ------------------ 9.7/18.4 MB 3.2 MB/s eta 0:00:03\n","   ---------------------- ----------------- 10.5/18.4 MB 3.3 MB/s eta 0:00:03\n","   ------------------------ --------------- 11.3/18.4 MB 3.3 MB/s eta 0:00:03\n","   -------------------------- ------------- 12.1/18.4 MB 3.3 MB/s eta 0:00:02\n","   --------------------------- ------------ 12.6/18.4 MB 3.3 MB/s eta 0:00:02\n","   ----------------------------- ---------- 13.4/18.4 MB 3.3 MB/s eta 0:00:02\n","   ------------------------------- -------- 14.4/18.4 MB 3.4 MB/s eta 0:00:02\n","   --------------------------------- ------ 15.2/18.4 MB 3.4 MB/s eta 0:00:01\n","   ---------------------------------- ----- 16.0/18.4 MB 3.4 MB/s eta 0:00:01\n","   ------------------------------------- -- 17.0/18.4 MB 3.5 MB/s eta 0:00:01\n","   -------------------------------------- - 17.8/18.4 MB 3.5 MB/s eta 0:00:01\n","   ---------------------------------------- 18.4/18.4 MB 3.5 MB/s  0:00:05\n","Installing collected packages: PyMuPDF\n","Successfully installed PyMuPDF-1.26.6\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install PyMuPDF"]},{"cell_type":"markdown","id":"ecf4804a","metadata":{"id":"ecf4804a"},"source":["Another Package to Load PDF File"]},{"cell_type":"code","execution_count":null,"id":"020f16db","metadata":{"collapsed":true,"id":"020f16db","outputId":"48514af1-7078-4a80-d9e1-9223b9dd6ef4"},"outputs":[{"name":"stderr","output_type":"stream","text":["D:\\Gen AI Project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"data":{"text/plain":["[Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 0}, page_content='E k t a  Va t s\\nA s s i s t a n t  P r o f e s s o r,  D o c e n t\\nD e p a r t m e n t  o f  I n f o r m a t i o n  Te c h n o l o g y,  U p p s a l a  U n i v e r s i t y  ( U U )\\nB e i j e r  R e s e a r c h e r,  B e i j e r  L a b o r a t o r y  f o r  A I  R e s e a r c h ,  B e i j e r s t i f t e l s e n\\nIntroduction to Large Language Model (LLM)\\nA I  in  Phys ic s  Wor ks h op–  A p r il 11, 2025'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 1}, page_content='Navigating in the Artificial Intelligence Era\\nThe future?\\nImage generated using ChatGPT'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 2}, page_content='Navigating in the Artificial Intelligence Era\\nThe future?\\nHolographic displays, autonomous bicycles, drone deliveries\\nÅngström à UNGSTROM'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 3}, page_content='Navigating in the Artificial Intelligence Era\\nGenerative AI – Generating new content!\\nLearn patterns and structure of input data, and generate new samples that exhibit similar characteristics.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 4}, page_content='Artificial \\nIntelligence\\nGenerative \\nAI\\nAI Taxonomy\\nTechnology that enables computers and \\nmachines to simulate human intelligence \\nand problem-solving capabilities'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 5}, page_content='Artificial \\nIntelligence\\nMachine \\nLearning\\nDeep \\nLearning\\nGenerative \\nAI\\nAI Taxonomy\\nSubset of AI, focuses on developing \\nsystems that can learn from data \\nand make decisions based on data'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 6}, page_content='AI Evolution Through Decades\\nSource: sk hynix newsroom'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 7}, page_content='AI Evolution Through Decades\\n2024\\nThe Nobel Prizes in \\nPhysics and Chemistry \\ngoes to AI!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 8}, page_content=''),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 9}, page_content='Source – leewayhertz\\nSynthetic image generation\\nSORA: text-to-video model\\nText:\\nTurn the library into a spaceship.\\nOutput:\\nSource – Open AI, SORA\\nVideo generation!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 10}, page_content='Synthetic image generation\\nImage generation!\\nMidjourney\\nText-to-image models:\\nTwo dogs dressed like roman soldiers on a pirate ship looking at \\nNew York City through a spyglass\\nSource – Open AI, DALL·E -2\\nSource: Twitter, Benjamin Hilton\\nDALL·E\\nAn image of a cat enjoying sprinklers.\\nSource: Microsoft Copilot'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 11}, page_content='TTS: Text-to-song; STS: Speech-to-singing \\nSynthetic image generation\\nSource – leewayhertz'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 12}, page_content='Artificial \\nIntelligence\\nMachine \\nLearning\\nDeep \\nLearning\\nGenerative AI\\nLLMs\\nAI Taxonomy\\nSubset of ML, uses Artificial Neural Networks \\nto learn from data\\nSubset of AI, focuses on generating new \\ncontent\\nSpecific type of Generative AI model that \\nfocuses on generating human-like text\\nLLMs: Large Language Models'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 13}, page_content='Large Language Model (LLM)\\n• A type of language model'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 14}, page_content='Language Model\\n• Type of machine learning model trained to predict probability distribution over words\\nVi ses\\nimorgon  \\n0.5\\nsnart \\n \\n0.3 \\npå \\n \\n0.2\\n• Predicts the probability of a word in a sequence based on the previous word'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 15}, page_content='Language Model\\n• Type of machine learning model trained to predict probability distribution over words\\nVi ses\\nimorgon  \\n0.5\\nsnart \\n \\n0.3 \\npå \\n \\n0.2\\nGoogle search and advanced language models'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 16}, page_content='Language Model\\n• Classic definition: Probability distribution over a sequence of tokens\\n• For example, if vocabulary of a set of tokens is V = {ate, ball, cheese, mouse, the}, \\na language model p might assign:\\n \\n \\np(!\"#, $%&\\'#, (!#, !\"#, )\"##\\'#) = 0.02,\\n \\n \\np(!\"#, )\"##\\'#, (!#, !\"#, $%&\\'#) = 0.01,\\n \\n \\np($%&\\'#, !\"#, !\"#, )\"##\\'#, (!#) = 0.0001.\\n \\nSource: https://stanford-cs324.github.io/winter2022/lectures/introduction/'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 17}, page_content='Language Model\\n• Classic definition: Probability distribution over a sequence of tokens\\n• For example, if vocabulary of a set of tokens is V = {ate, ball, cheese, mouse, the}, \\na language model p might assign:\\n \\n \\np(!\"#, $%&\\'#, (!#, !\"#, )\"##\\'#) = 0.02,\\n \\n \\np(!\"#, )\"##\\'#, (!#, !\"#, $%&\\'#) = 0.01,\\n \\n \\np($%&\\'#, !\"#, !\"#, )\"##\\'#, (!#) = 0.0001.\\n• Example: Neural language models - RNNs including LSTMs, Transformers\\n \\n \\np(cheese | (!#, !\"#) = some-neural-network(ate, the, cheese)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 18}, page_content='Large Language Model (LLM)\\n• A type of language model\\n• Why large: \\n• Trained using massive datasets\\n• With the rise of deep learning and availability of large computational resources, the size of \\nneural language models has increased.\\nImage source: nsc.liu.se\\nBerzelius!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 19}, page_content='Large Language Model (LLM)\\nSource – cobusgreyling.medium.com\\n2018\\n2023\\n2025: GPT-5?\\nScaling-up – \\nbigger is better?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 20}, page_content='Architecture\\n• LLM is a type of transformer model\\n• Transformer: \\n• A neural network that learns context and meaning \\nby tracking relationships in sequential data'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 21}, page_content='Architecture\\n• LLM is a type of transformer model\\n• Transformer: \\n• A neural network that learns context and meaning \\nby tracking relationships in sequential data\\n• Encoder-decoder architecture\\n• Encoder extracts features from an input sequence\\n• Decoder uses the features to produce an output \\nsentence\\nHur mår du?\\nHow are you?\\nCase: translation\\n(input)\\n(output)\\nTRANSFORMER'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 22}, page_content='Architecture\\n• LLM is a type of transformer model\\n• Transformer: \\n• A neural network that learns context and meaning \\nby tracking relationships in sequential data\\n• Encoder-decoder architecture\\n• Encoder extracts features from an input sequence\\n• Decoder uses the features to produce an output \\nsentence\\n(input)\\n(output)\\nCan be used independently!\\nTRANSFORMER\\nCase: translation\\nHur mår du?\\nHow are you?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 23}, page_content='Transformer – Recommended Reading\\n• Transformers by Lucas Beyer\\n• Link: https://www.youtube.com/watch?v=EixI6t5oif0\\n• Deep Learning course (1RT720)\\n• Given in period 3\\n• Course responsible: Niklas Wahlström\\n• LLMs & Societal Consequences of AI  (1RT730)\\n• Given in period 1\\n• Course responsible: Ekta Vats'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 24}, page_content='Types of LLMs'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 25}, page_content='Types of LLMs\\n• Encoder only: \\n• Suited for tasks that can understand language, \\n• such as toxicity classification and sentiment analysis. \\n• Example: BERT (Bidirectional Encoder Representations from Transformers)\\nSentiment analysis of tweets'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 26}, page_content='Types of LLMs\\n• Decoder only: \\n• Suited for generating language and content, \\n• such as story writing, blog generation, open-domain Q/A and virtual assistants.\\n• Example: GPT-3 (Generative Pretrained Transformer 3)\\nChatBots'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 27}, page_content=''),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 28}, page_content='Types of LLMs\\n• Encoder-decoder: \\n• Combine the encoder and decoder components of the transformer architecture\\n• Suited for both understanding and generating content, \\n• such as translation, text-to-code and summarisations. \\n• Example: T5 (Text-to-Text Transformers) by HuggingFace'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 29}, page_content='Types of LLMs\\n• Encoder-decoder: \\n• Example: T5 (Text-to-Text Transformers) by HuggingFace.\\nT5\\n“Translate English to Swedish: Thank you very much.” \\n“Tack så mycket.”'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 30}, page_content='Types of LLMs\\n• Encoder-decoder: \\n• Example: T5 (Text-to-Text Transformers) by HuggingFace.\\nT5\\n“summarize: Sweden became NATO’s newest member on Thursday (7 March 2024), \\nupon depositing its instrument of accession to the North Atlantic Treaty with the \\nGovernment of the United States in Washington DC. With Sweden’s accession, NATO \\nnow counts 32 countries among its members.” \\n“Sweden joined NATO on March 7, 2024, becoming its 32nd member.”'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 31}, page_content='LLM Lifecycle'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 32}, page_content='LLM Lifecycle\\n1.\\nCollect training data – e.g. Common Crawl\\n2.\\nTrain a LLM – e.g. GPT-3\\n3.\\nAdapt it for downstream tasks – e.g. Q/A\\n4.\\nDeploy LLM to users – e.g. Chatbot'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 33}, page_content='Important\\nData is the fuel!\\nAI is the engine!\\n• To understand and document the composition of your training dataset\\nFurther reading: https://stanford-cs324.github.io/winter2022/lectures/legality/'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 34}, page_content='Important\\n• To understand and document the composition of your training dataset\\n• To be aware of copyright law (IPR, licenses), privacy law, high-risk applications\\n• Is training LLM on this data a copyright/privacy violation?\\n• Can it cause intentional harm – spam, harassment, disinformation, phishing attacks?\\n• Are you deploying LLM in healthcare or education?\\n• Github code and licensing\\nFurther reading: https://stanford-cs324.github.io/winter2022/lectures/legality/'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 35}, page_content='Multimodal LLMs'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 36}, page_content='Multimodal LLMs\\n• Unimodal LLMs are trained on a single modality of data, such as text\\n• Lack visual context'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 37}, page_content='Multimodal LLMs\\n• Unimodal LLMs are trained on a single modality of data, such as text\\n• Lack visual context\\n• Multimodal LLMs: \\n• Understand and generate content across multiple modalities,\\n• such as text, images, audio, video, or other sensor data\\n• Vision-language models: \\n• Multimodal models that can learn from images and text'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 38}, page_content='Vision-Language Models\\n• Main idea: Unify the image and text representation, and feed it to a textual decoder for \\ngeneration'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 39}, page_content='Vision-Language Models\\n• Main idea: Unify the image and text representation, and feed it to a textual decoder for \\ngeneration\\n• Typically consists of two main components: \\n• Vision encoder: extracts image features and encodes them into a format that can be understood \\nby the language decoder. Example: ResNet, ViT\\n• Language decoder: takes these encoded visual features along with any textual input and \\ngenerates descriptions, or captions, etc. Example: GPT-2, GPT-3'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 40}, page_content='Vision-Language Models\\nhttps://huggingface.co/blog/vlms'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 41}, page_content='Vision-Language Models\\nhttps://huggingface.co/blog/vlms'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 42}, page_content='Contrastive Language-Image Pretraining (CLIP)\\n• CLIP differs from traditional vision-language models \\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\" International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 43}, page_content='Contrastive Language-Image Pretraining (CLIP)\\n• CLIP differs from traditional vision-language models \\n• It does not generate text descriptions or captions for images\\n• Focuses on learning a joint representation space where images and text can be compared directly\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\" International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 44}, page_content='Contrastive Language-Image Pretraining (CLIP)\\n• CLIP differs from traditional vision-language models \\n• It does not generate text descriptions or captions for images\\n• Focuses on learning a joint representation space where images and text can be compared directly\\n• Enables various downstream tasks, such as \\n• Zero-shot image classification: classify images into one of several classes, without any prior \\ntraining or knowledge of the classes\\n• Zero-shot image retrieval, text-based image generation\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\" International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 45}, page_content='Contrastive Language-Image Pretraining (CLIP)\\n1.\\nJointly trains a text encoder and an image encoder to predict the correct image—text pair\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\" International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 46}, page_content='Contrastive Language-Image Pretraining (CLIP)\\n1.\\nJointly trains a text encoder and an image encoder to predict the correct image—text pair\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\" International conference on machine learning. PMLR, 2021.\\nContrastive Pre-training\\nText embeddings\\nImage embeddings\\nTransformer\\n(ResNet or ViT)\\nContrastive learning framework\\n•\\nMaximize the cosine similarities between \\ncorrect image-text pairs\\n•\\nMinimize the cosine similarities for \\ndissimilar pairs (non-diagonal elements)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 47}, page_content='Contrastive Language-Image Pretraining (CLIP)\\n2.\\nConverts training dataset classes into captions\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\" International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 48}, page_content='Contrastive Language-Image Pretraining (CLIP)\\n3.\\nEstimates the best caption for the given input image for zero-shot prediction\\n• Calculate similarity between an image vector and multiple caption vectors, selecting the \\none with the highest score\\nRadford, Alec, et al. \"Learning transferable visual models from natural language supervision.\" International conference on machine learning. PMLR, 2021.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 49}, page_content='Contrastive Language-Image Pretraining (CLIP)\\n3.\\nEstimates the best caption for the given input image for zero-shot prediction\\n• Calculate similarity between an image vector and multiple caption vectors, selecting the \\none with the highest score\\n•\\nTrained on 400M image-text pairs\\n•\\nCLIP can perform image tasks using only text, no extra training needed\\n•\\nCLIP encodings + decoder models (e.g. GPT-2) => image captioning'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 50}, page_content='Some Interesting Examples'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 51}, page_content='Modern Handwriting Recognition using ChatGPT\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Can you recognise this text?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 52}, page_content='Modern Handwriting Recognition using ChatGPT\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Can you recognise this text?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 53}, page_content='Old Handwriting Recognition using ChatGPT\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Can you read this?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 54}, page_content='Old Handwriting Recognition using ChatGPT\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Can you read this?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 55}, page_content='Ancient Handwriting Recognition using Microsoft Copilot\\nNota bene is the Latin phrase meaning note well'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 56}, page_content='OCR and Document Question Answering\\n• Text…\\nhttps://huggingface.co/docs/transformers/main/en/tasks/document_question_answering\\nQuestion: Who is in cc in this letter? \\nAnswer: T.F. Riehl'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 57}, page_content='Understanding Complex Parking Signs – ChatGPT\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Suppose it is Wednesday and the time is 4PM. Am I allowed to park my car at this spot?\\nAnyone?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 58}, page_content='Understanding Complex Parking Signs – GPT-4V\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nPrompt: Suppose it is Wednesday and the time is 4PM. Am I allowed to park my car at this spot?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 59}, page_content='Visual Question Answering\\nMarino, Kenneth, et al. \"Ok-vqa: A visual question answering benchmark requiring external knowledge.\" Proceedings of the IEEE/cvf conference on computer vision and pattern recognition. 2019.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 60}, page_content='Visual Question Answering\\nLiu, Haotian, et al. \"Visual instruction tuning.\" Advances in neural information processing systems 36 (2024).\\nLLaVA: Large Language and Vision Assistant - CLIP visual encoder + Vicuna LLM'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 61}, page_content='Visual Question Answering\\nSource: Medium article on Exploring Multimodal Large Language Models: A Step Forward in AI\\nLLaVA: Large Language and Vision Assistant - CLIP visual encoder + Vicuna LLM'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 62}, page_content='Whisper by OpenAI\\n• Speech-to-text model, performs:\\n• Speech recognition\\n• Speech translation\\n• Spoken language identification\\n• Voice activity detection'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 63}, page_content='Focus: Swedish speech\\nImage source: LinkedIn'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 64}, page_content='LLMs and Video Analysis\\nPlatform: Azure AI'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 65}, page_content='Challenges and limitations'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 66}, page_content='Challenges and Limitations\\n• Out-of-date training data\\nThis example was tested on 10 March, 2025'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 67}, page_content='Challenges and Limitations\\n• Hallucinations\\n•\\nFacts are sometimes extrapolated, \\n•\\nLLMs try to invent facts, \\n•\\narticulating the inaccurate information in a convincing way.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 68}, page_content='Challenges and Limitations\\n• Hallucinations\\n•\\nFacts are sometimes extrapolated, \\n•\\nLLMs try to invent facts, \\n•\\narticulating the inaccurate information in a convincing way.\\nThis example was tested in Spring 2024'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 69}, page_content='Challenges and Limitations\\n• Hallucinations\\n•\\nFacts are sometimes extrapolated, \\n•\\nLLMs try to invent facts, \\n•\\narticulating the inaccurate information in a convincing way.\\nTested: October 2024'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 70}, page_content='Challenges and Limitations\\nTested: March 2025'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 71}, page_content='Challenges and Limitations\\n• Hallucinations'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 72}, page_content='Challenges and Limitations\\n• Hallucinations\\nWhat is the correct answer?'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 73}, page_content='Challenges and Limitations\\n• Hallucinations\\n• It is a language model!\\n• Training data lacks focus on math concepts and problem-solving.\\n5,162,060'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 74}, page_content='Hallucinations, Case – Law\\nThis example was shared by a lawyer'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 75}, page_content='Hallucinations, Case – Law\\nThis example was shared by a lawyer'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 76}, page_content='Hallucinations, Case – Law\\nMicrosoft Copilot did not hallucinate!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 77}, page_content='Hallucinations, Case – MiniGPT-4\\nSource: MiniGPT-4 by HuggingFace'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 78}, page_content='Hallucinations, Case – MiniGPT-4\\nSource: MiniGPT-4 by HuggingFace'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 79}, page_content='Hallucinations, Case - HTRFlow\\nHTRFlow model\\nBevittna  \\n(Bevittna translates to witness)\\nSource: https://huggingface.co/spaces/Riksarkivet/htr_demo (2023)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 80}, page_content='Potential Solution: Retrieval Augmented Generation (RAG)\\n• Helps address both hallucinations and out-of-date training data issues'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 81}, page_content='Retrieval Augmented Generation (RAG)\\n• Build LLMs with current and reliable information\\n• Extending its utility to specific data sources\\n• Allows LLMs to go beyond their knowledge-base, enabling them to access real-time \\ndata, and providing up to date responses\\n• Example use case: Improve Math Q/A'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 82}, page_content='Retrieval Augmented Generation (RAG)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 83}, page_content='Retrieval Augmented Generation (RAG)\\nThis example was on 10 March, 2025'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 84}, page_content='RAG Example Projects from UU course on LLMs\\n• Teaching LLM to teach AI'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 85}, page_content='RAG Example Projects from UU course on LLMs\\n• Teaching LLM to teach AI \\n• Chat with 1177.se'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 86}, page_content='RAG Example Projects from UU course on LLMs\\n• Teaching LLM to teach AI \\n• Chat with 1177.se\\n• LLM powered teaching assistant for Smarter Education\\n• Exercise sheet generation\\n• Based on age, grade and interest of the child'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 87}, page_content='Challenges and Limitations\\n• Bias and misinformation as ethical concerns\\nSocial Biases in Language Models: http://uu.diva-portal.org/smash/get/diva2:1696604/FULLTEXT01.pdf'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 88}, page_content=\"Challenges and Limitations\\n• Bias and misinformation as ethical concerns\\n• Key pointer: \\n• LLM has inherited society's stereotypes due to the training data being fed into it.\\n• Other cases: voice assistants and FaceID\"),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 89}, page_content='Voice Assistants and Accent Bias\\nSource: https://www.amazon.science/blog/how-alexa-learned-to-speak-with-an-irish-accent (2023)\\n• Data problem!\\n• The higher the quantity and diversity of speech samples in a corpus, the more accurate \\nthe resulting model\\nAmazon researchers improved Irish-accented training data by using a voice conversion model'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 90}, page_content='Face ID and Limitations\\nSource: https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212  (2018)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 91}, page_content='Face ID and Limitations\\nSource: https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212  (2018)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 92}, page_content='Face ID and Limitations\\n• This bias arise from the imbalance in the training data\\n• Lighting conditions: Darker skin tones might reflect less light, potentially affecting \\nrecognition accuracy'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 93}, page_content='Face ID and Limitations\\n• This bias arise from the imbalance in the training data\\n• Lighting conditions: Darker skin tones might reflect less light, potentially affecting \\nrecognition accuracy\\n• Modern face recognition systems:\\n• Diverse training data\\n• Algorithmic improvements \\n• Aim to achieve robust performance, regardless of skin tone or lighting conditions.\\n• Biases can still persist'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 94}, page_content='Future Insights!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 95}, page_content='Future Insights!\\nScaling-up – bigger is better?\\n•\\nQuantitatively: different capabilities\\n•\\nQualitatively: different societal impact'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 96}, page_content='Future Insights!\\nScaling-up – bigger is better?\\nIn-Context Learning\\nhttps://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec04.pdf\\nZero-shot\\nOne-shot\\nFew-shot'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 97}, page_content='Future Insights!\\nScaling-up – bigger is better?\\nIn-Context Learning\\nAI powered precision in healthcare\\nAnalyse medical images, and using LLMs correlate medical findings with patient \\nhistory, delivering comprehensive diagnostics and potential treatment options. \\nAlso… Applications in Physics!'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 98}, page_content='Advanced Multimodal LLMs\\n• Example: NExT-GPT (Any-to-Any Multimodal LLM)\\n• Text + Video à Text + Image\\nhttps://next-gpt.github.io\\nImageBind by Meta\\n6 modalities:\\nImages/videos,\\nAudio, Text,\\nDepth, Thermal,\\nInertial measurement units (IMUs)\\n+ \\nDiffusion Models (generation)'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 99}, page_content='You can select “off” for this option, \\nin your ChatGPT settings.'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 100}, page_content='We conducted an exam for \\n• Total 10 questions\\n• Following are our findings:\\n• Both excel in creative thinking, image generation and summarization. \\n• ChatGPT struggles with legal reasoning but excels in math. \\n• Neither handles old handwriting well.\\n• Overall, score for Copilot was higher.\\n• Curious to know how it works in Physics…\\nLink'),\n"," Document(metadata={'producer': 'macOS Version 15.4 (Build 24E248) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20250411085308Z00'00'\", 'source': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'file_path': 'D:\\\\Gen AI Project\\\\venv\\\\LangChain\\\\Input Files\\\\UU_EktaVats_AI_Physics.pdf', 'total_pages': 102, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250411085308Z00'00'\", 'trapped': '', 'modDate': \"D:20250411085308Z00'00'\", 'creationDate': \"D:20250411085308Z00'00'\", 'page': 101}, page_content='Thank you!\\nEmail    : ekta.vats@it.uu.se\\nWebpage: https://www.ektavats.se')]"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_community.document_loaders import PyMuPDFLoader\n","\n","test_2 = PyMuPDFLoader(r\"D:\\Gen AI Project\\venv\\LangChain\\Input Files\\UU_EktaVats_AI_Physics.pdf\")\n","\n","test_2.load()"]},{"cell_type":"code","execution_count":null,"id":"b75e0e21","metadata":{"collapsed":true,"id":"b75e0e21","outputId":"3a7b2fbe-225a-4a03-cb8f-7ddc9a8a854b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting bs4\n","  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n","Collecting beautifulsoup4 (from bs4)\n","  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n","Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n","  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: typing-extensions>=4.0.0 in d:\\gen ai project\\venv\\lib\\site-packages (from beautifulsoup4->bs4) (4.15.0)\n","Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n","Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n","Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n","Installing collected packages: soupsieve, beautifulsoup4, bs4\n","\n","   ---------------------------------------- 3/3 [bs4]\n","\n","Successfully installed beautifulsoup4-4.14.2 bs4-0.0.2 soupsieve-2.8\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install bs4"]},{"cell_type":"markdown","id":"8324385f","metadata":{"id":"8324385f"},"source":["Loading a Content from Website"]},{"cell_type":"code","execution_count":null,"id":"2341fed3","metadata":{"collapsed":true,"id":"2341fed3","outputId":"05142109-cf88-42ff-dc18-0a180f2b1bea"},"outputs":[{"name":"stderr","output_type":"stream","text":["D:\\Gen AI Project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","USER_AGENT environment variable not set, consider setting it to identify your requests.\n","USER_AGENT environment variable not set, consider setting it to identify your requests.\n"]},{"data":{"text/plain":["[Document(metadata={'source': 'https://www.geeksforgeeks.org/artificial-intelligence/large-language-model-llm/', 'title': 'What is a Large Language Model (LLM) - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat is a Large Language Model (LLM) - GeeksforGeeks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCoursesDSA / PlacementsGATE PrepML & Data ScienceDevelopmentCloud / DevOpsProgramming LanguagesAll CoursesTutorialsPythonJavaDSAML & Data ScienceInterview CornerProgramming LanguagesWeb DevelopmentGATECS SubjectsDevOpsSchool LearningSoftware and ToolsPracticePractice Coding ProblemsNation Skillup- Free CoursesProblem of the DayBuild AI Agent (Free)StudyIn: Global ContestJobsApply Now!Post JobsJobs Updates\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotifications\\n\\nMark all as read\\n\\n\\n\\n\\n\\nAll\\n\\n\\n\\n\\n\\n \\n\\nView All\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotifications\\n\\n\\n\\nMark all as read\\n\\n\\n\\n\\n\\n\\nAll\\n\\n\\nUnread\\n\\n\\nRead\\n\\n\\n\\n\\n\\r\\n                        You're all caught up!!\\r\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArtificial IntelligenceInterview QuestionsProject IdeasSearch AlgorithmsLocal Search AlgorithmGenerative AIData ScienceMachine LearningDeep LearningML-ProjectsRobotics \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign In\\n\\n\\n▲\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpen In App\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nExplore GfG Connect NewShare Your ExperiencesIntroduction to AIWhat is Artificial Intelligence (AI)Types of Artificial Intelligence (AI)Types of AI Based on FunctionalitiesAgents in AIArtificial intelligence vs Machine Learning vs Deep LearningProblem Solving in Artificial IntelligenceTop 20 Applications of Artificial Intelligence (AI) in 2025AI ConceptsSearch Algorithms in AILocal Search Algorithm in Artificial IntelligenceAdversarial Search Algorithms in Artificial Intelligence (AI)Constraint Satisfaction Problems (CSP) in Artificial IntelligenceKnowledge Representation in AIFirst-Order Logic in Artificial IntelligenceReasoning Mechanisms in AIMachine Learning in AIMachine Learning TutorialDeep Learning TutorialNatural Language Processing (NLP) TutorialComputer Vision TutorialRobotics and AIArtificial Intelligence in RoboticsWhat is Robotics Process AutomationAutomated Planning in AIAI in TransportationAI in Manufacturing : Revolutionizing the IndustryGenerative AIWhat is Generative AI?Generative Adversarial Network (GAN)Cycle Generative Adversarial Network (CycleGAN)StyleGAN - Style Generative Adversarial NetworksIntroduction to Generative Pre-trained Transformer (GPT)BERT Model - NLPGenerative AI Applications AI PracticeTop Artificial Intelligence(AI) Interview Questions and AnswersTop Generative AI and LLM  Interview Question with Answer30+ Best Artificial Intelligence Project Ideas with Source Code [2025 Updated]Generative AICourse \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat is a Large Language Model (LLM)\\n\\n\\n\\nLast Updated : \\n18 Sep, 2025\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n\\n\\n\\n\\n19 Likes\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReport\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLarge Language Models (LLMs) are advanced AI systems built on deep neural networks designed to process, understand and generate human-like text. By using massive datasets and billions of parameters, LLMs have transformed the way humans interact with technology. It learns patterns, grammar and context from text and can answer questions, write content, translate languages and many more. Mordern LLMs include ChatGPT (OpenAI), Google Gemini, Anthropic Claude, etcLLMTo explore the technical concepts behind LLMs, understand how they work, what they can do and how to build projects using them, refer to our Large Language Model (LLM) Tutorial.Working of LLM LLMs are primarily based on the Transformer architecture which enables them to learn long-range dependencies and contextual meaning in text. At a high level, they work through:WorkingInput Embeddings: Converting text into numerical vectors.Positional Encoding: Adding sequence/order information.Self-Attention: Understanding relationships between words in context.Feed-Forward Layers: Capturing complex patterns.Decoding: Generating responses step-by-step.Multi-Head Attention: Parallel reasoning over multiple relationships.To know more about transformers architecture refer to: Architecture and Working of Transformers in Deep LearningArchitectureThe architecture of LLMs consist of multiple stacked layers that process text in parallel. Core components include:Embedding Layer: Converts tokens i.e words/subwords into dense vectors.Attention Mechanism: Learns context by focusing on relevant words.Feed-Forward Layers: Capture non-linear patterns and relationships.Normalization and Residual Connections: Improve training stability.Output Layer: Generates predictions such as the next word or sentence.To know more about the architecture of LLM, read LLM Architecture.Popular LLMsSome of the most widely used LLMs include:GPT-4 and GPT-4o (OpenAI): Advanced multimodal reasoning and dialogue capabilities.Gemini 1.5 (Google DeepMind): Long-context reasoning, capable of handling 1M+ tokens.Claude 3 (Anthropic): Safety-focused, strong at reasoning and summarization.LLaMA 3 (Meta): Open-weight model, popular in research and startups.Mistral 7B / Mixtral (Mistral AI): Efficient open-source alternatives for developers.BERT and RoBERTa (Google/Facebook): Strong embedding models for NLP tasks.mBERT and XLM-R: Early multilingual LLMs.BLOOM: Large open-source multilingual model, collaboratively developed.Use CasesCode Generation: LLMs can generate accurate code based on user instructions for specific tasks.Debugging and Documentation: They assist in identifying code errors, suggesting fixes and even automating project documentation.Question Answering: Users can ask both casual and complex questions, receiving detailed, context-aware responses.Language Translation and Correction: LLMs can translate text between over 50 languages and correct grammatical errors.Prompt-Based Versatility: By crafting creative prompts, users can unlock endless possibilities, as LLMs excel in one-shot and zero-shot learning scenarios. Advantages Large Language Models (LLMs) come with several advantages that contribute to their widespread adoption and success in various applications:Zero-Shot and Few-Shot Learning: Can perform new tasks without explicit retraining.Scalable Knowledge: Efficiently process and understand vast text corpora.Fine-Tuning Flexibility: Adaptable to specific industries and datasets.Automation of Language Tasks: Frees human effort from repetitive or time-consuming tasks.Versatility: Effective across multiple domains—healthcare, education, business and research.ChallengesHigh Costs: Training requires millions of dollars in compute resources.Time-Intensive: Training large models can take weeks or months.Data Challenges: Limited availability of high-quality, legal and unbiased text data.Environmental Impact: High energy consumption leading to significant carbon footprint.Ethical Concerns: Bias, misinformation risks and responsible deployment remains a major issue. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCreate Quiz\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        Comment\\r\\n    \\n\\n\\n\\n\\n\\nA\\n\\n\\n\\n\\n\\nabhishekm482g\\n\\n\\n\\n\\n\\n Follow\\n\\n\\n\\n\\n\\n\\n19\\n\\n\\nImprove\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nA\\n\\n\\n\\n\\n \\n\\nabhishekm482g \\n\\n\\n\\n\\n\\n Follow \\n\\n\\n\\n\\n\\n\\n\\n\\n19\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\nArticle Tags : \\n\\n\\nArtificial Intelligence\\n\\n\\ndata-science\\n\\n\\nChatGPT\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4k+ interested Geeks \\n\\n\\n\\nGATE CSE 2028 Online Course [Live Classes + Recorded] \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n7k+ interested Geeks \\n\\n\\n\\nGATE DA Complete Course 2026 [ Live Weekend Classes] \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2k+ interested Geeks \\n\\n\\n\\nGATE CS/IT 2028 Complete Course [with Placement Preparation] \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCorporate & Communications Address:\\n\\r\\n                      A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)                    \\n\\n\\n\\n\\n\\nRegistered Address:\\r\\n                        K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCompanyAbout UsLegalPrivacy PolicyCareersContact UsCorporate SolutionCampus Training ProgramExplorePOTDJob-A-ThonConnectBlogsNation Skill UpTutorialsProgramming LanguagesDSAWeb TechnologyAI, ML & Data ScienceDevOpsCS Core SubjectsGATESchool SubjectsSoftware and ToolsCoursesIBM CertificationDSA and PlacementsWeb DevelopmentData ScienceProgramming LanguagesDevOps & CloudGATETrending TechnologiesOffline CentersNoidaBengaluruPuneHyderabadPatnaPreparation CornerInterview CornerAptitudePuzzlesGfG 160System Design \\n\\n\\n\\n\\n\\n\\n@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nImprovement\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n\\n\\n\\nSuggest Changes\\nHelp us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.\\n\\n\\n\\n\\n\\n\\n\\nCreate Improvement\\nEnhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest Changes\\n\\n\\n\\n\\n\\n\\nmin 4 words, max Words Limit:1000\\n\\n\\n\\n\\nThank You!\\nYour suggestions are valuable to us.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat kind of Experience do you want to share?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInterview Experiences\\n\\n\\n\\n\\n\\n\\n\\nAdmission Experiences\\n\\n\\n\\n\\n\\n\\n\\nCareer Journeys\\n\\n\\n\\n\\n\\n\\n\\nWork Experiences\\n\\n\\n\\n\\n\\n\\n\\nCampus Experiences\\n\\n\\n\\n\\n\\n\\n\\nCompetitive Exam Experiences\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_community.document_loaders import WebBaseLoader\n","\n","test_3 = WebBaseLoader(web_path=\"https://www.geeksforgeeks.org/artificial-intelligence/large-language-model-llm/\")\n","\n","test_3.load()"]},{"cell_type":"markdown","id":"7c312bb1","metadata":{"id":"7c312bb1"},"source":["Loading Content from IEEE Research Papers"]},{"cell_type":"code","source":["%pip install pymupdf\n","%pip install arxiv"],"metadata":{"id":"QC5hYbEN4hhe"},"id":"QC5hYbEN4hhe","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"e0d0328d","metadata":{"id":"e0d0328d"},"outputs":[],"source":["from langchain_community.document_loaders import ArxivLoader\n","\n","test4 = ArxivLoader(query=\"1706.03762\")\n","\n","test4.load()"]},{"cell_type":"markdown","source":["Loading Content from Wikipedia Website"],"metadata":{"id":"M2D-nNAU4wTI"},"id":"M2D-nNAU4wTI"},{"cell_type":"code","execution_count":null,"id":"9d7a40fe","metadata":{"collapsed":true,"id":"9d7a40fe","outputId":"c72bd306-fdb5-4810-f780-d2287d9cfde9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting arxiv\n","  Downloading arxiv-2.3.1-py3-none-any.whl.metadata (5.2 kB)\n","Collecting feedparser~=6.0.10 (from arxiv)\n","  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: requests~=2.32.0 in d:\\gen ai project\\venv\\lib\\site-packages (from arxiv) (2.32.5)\n","Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n","  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Requirement already satisfied: charset_normalizer<4,>=2 in d:\\gen ai project\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in d:\\gen ai project\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\gen ai project\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in d:\\gen ai project\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2025.10.5)\n","Downloading arxiv-2.3.1-py3-none-any.whl (11 kB)\n","Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n","Building wheels for collected packages: sgmllib3k\n","  Building wheel for sgmllib3k (pyproject.toml): started\n","  Building wheel for sgmllib3k (pyproject.toml): finished with status 'done'\n","  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6105 sha256=592d2262366396c7f6492e18c7245cfdfd05e2e42ecbc5e77c95d2879780d1a9\n","  Stored in directory: c:\\users\\sathi\\appdata\\local\\pip\\cache\\wheels\\3b\\25\\2a\\105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n","Successfully built sgmllib3k\n","Installing collected packages: sgmllib3k, feedparser, arxiv\n","\n","   ---------------------------------------- 3/3 [arxiv]\n","\n","Successfully installed arxiv-2.3.1 feedparser-6.0.12 sgmllib3k-1.0.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install wikipedia"]},{"cell_type":"code","execution_count":null,"id":"4e0cdcea","metadata":{"id":"4e0cdcea"},"outputs":[],"source":["from langchain_community.document_loaders import WikipediaLoader\n","\n","test5 = WikipediaLoader(query=\"Generative AI\", load_max_docs=2)\n","\n","test5.load()"]},{"cell_type":"markdown","source":[],"metadata":{"id":"W1AoQ_k_4VKZ"},"id":"W1AoQ_k_4VKZ"}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}